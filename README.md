# PACMAM: Passive or active monitoring and auditing of models 
**French ANR project 2024->2028 (ANR-24-CE23-7787)**

![ANR logo](https://anr.fr/typo3conf/ext/anr_skin/Resources/Public/assets/img/anr-logo-2021-complet.png)

url: [bit.ly/PACMAM](https://bit.ly/PACMAM)

## Objectives
*We are today surrounded by algorithms that make decisions on our behalf. These algorithms,
often powered by complex machine learning models, operate as black boxes: their internal processes
are opaque to end users and auditors (who are in charge of enforcing the fairness of these models).
In this context, the PACMAM project seeks to increase the transparency of algorithmic decisions
by laying the foundations for efficient black-box auditing of large-capacity models under budget
constraints. The project will focus on active learning strategies for auditing that have recently
been introduced in the literature, yet whose applicability to concrete cases remains uncertain. The
proposed research is organized in three work packages (WPs), each of which addresses a fundamental
challenge in this research area. WP1 aims to understand how audit efficiency is affected by a model’s
capacity, leveraging measures such as VC dimension and Rademacher complexity. This information
will help auditors strike a balance between query budget and accuracy. Building on WP1, WP2
focuses on making active auditing practical for large-capacity models by identifying efficient ways to
select optimal inputs and determining what auditors need to know about audited models to succeed.
Finally, WP3 explores how models that are frequently updated can be monitored efficiently. The
goal is to reduce the query budget needed to continuously monitor an evolving model. Overall,
PACMAM will thus provide the foundation for the efficient auditing of evolving high-capacity
models. The project will ensure that any developed solutions is implemented rapidly thanks to the
involvement of PEReN, the French government’s department in charge of algorithmic regulation.*

## Backed-up papers

* [Log Probability Tracking of LLM APIs, in ICLR 2026](https://arxiv.org/html/2512.03816v1)
* [P2NIA: Privacy-Preserving Non-Iterative Auditing, Jade Garcia Bourrée, Hadrien Lautraite, Sébastien Gambs, Gilles Tredan, Erwan Le Merrer, Benoît Rottembourg, in ECML/PKDD 2025](https://arxiv.org/abs/2504.00874)
* [Robust ML Auditing using Prior Knowledge, Jade Garcia Bourrée, Augustin Godinot, Martijn De Vos, Milos Vujasinovic, Sayan Biswas, Gilles Tredan, Erwan Le Merrer, Anne-Marie Kermarrec, in ICML 2025](https://arxiv.org/pdf/2505.04796)
* [Queries, Representation & Detection: The Next 100 Model Fingerprinting Schemes, Augustin Godinot, Erwan Le Merrer, Camilla Penzo, François Taïani, Gilles Trédan, in AAAI 2025](https://arxiv.org/abs/2412.13021)
* [LLMs hallucinate graphs too: a structural perspective, Erwan Le Merrer and Gilles Tredan, in Complex networks 2024.](https://arxiv.org/html/2409.00159v2) 

## Management
* Recruted Staff
  * Timothée Chauvin, Ph.D. candidate, started in Jan. 2nd 2025.
  * Marouane Bazzaoui, Ph.D. candidate, started in Feb. 1rst 2026.

## Contacts
Gilles Tredan, LAAS/CNRS (Project lead)\
Erwan Le Merrer, Inria\
PEReN, Gohar Dashyan

